{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef674a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17250f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/NLP_class/lab4/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9800e08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "\n",
      " id                            int64\n",
      "title                        object\n",
      "body                         object\n",
      "answer_count                  int64\n",
      "comment_count                 int64\n",
      "creation_date                object\n",
      "last_activity_date           object\n",
      "last_editor_display_name     object\n",
      "owner_display_name           object\n",
      "owner_user_id               float64\n",
      "post_type_id                  int64\n",
      "score                         int64\n",
      "tags                         object\n",
      "view_count                    int64\n",
      "accepted_answer_id          float64\n",
      "favorite_count              float64\n",
      "last_edit_date               object\n",
      "last_editor_user_id         float64\n",
      "community_owned_date         object\n",
      "dtype: object\n",
      "Number of questions,columns= (20000, 19)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# read json into a dataframe\n",
    "df_idf=pd.read_json(\"stackoverflow-data-idf.json\",lines=True)\n",
    "# print schema\n",
    "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
    "print(\"Number of questions,columns=\",df_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de628c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gradle command line i m trying to run a shell script with gradle i currently have something like this def test project tasks create test exec commandline bash c bash c my file dir script sh the problem is that i cannot run this script because i have spaces in my dir name i have tried everything e g commandline bash c bash c my file dir script sh tokenize commandline bash c bash c my file dir script sh commandline bash c new stringbuilder append bash append c my file dir script sh commandline bash c bash c my file dir script sh file dir file c my file dir script sh commandline bash c bash dir getabsolutepath im using windows bit and if i use a path without spaces the script runs perfectly therefore the only issue as i can see is how gradle handles spaces '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_idf['text'] = df_idf['title'] + df_idf['body']\n",
    "df_idf['text'] = df_idf['text'].apply(pre_process)\n",
    "\n",
    "#show the first 'text'\n",
    "df_idf['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eefd375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "\n",
    "#load a set of stop words\n",
    "stopwords=get_stop_words(\"stopwords.txt\")\n",
    "\n",
    "#get the text column \n",
    "docs=df_idf['text'].tolist()\n",
    "\n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents, \n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=list(stopwords))\n",
    "word_count_vector=cv.fit_transform(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad19e68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 124901)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ea4ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(max_df=0.85,stop_words=list(stopwords),max_features=10000)\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da3e9653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serializing',\n",
       " 'private',\n",
       " 'struct',\n",
       " 'public',\n",
       " 'class',\n",
       " 'contains',\n",
       " 'properties',\n",
       " 'string',\n",
       " 'serialize',\n",
       " 'attempt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b060c669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customization',\n",
       " 'customize',\n",
       " 'customized',\n",
       " 'customlog',\n",
       " 'customview',\n",
       " 'cut',\n",
       " 'cv',\n",
       " 'cv_',\n",
       " 'cval',\n",
       " 'cvc',\n",
       " 'cw',\n",
       " 'cwd',\n",
       " 'cx',\n",
       " 'cx_oracle',\n",
       " 'cxf']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.get_feature_names_out())[2000:2015]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc91c42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfTransformer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5db4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.37717703,  9.80492526,  9.51724319, ...,  8.82409601,\n",
       "       10.21039037,  9.51724319])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1902dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test docs into a dataframe and concatenate title and body\n",
    "df_test=pd.read_json(\"stackoverflow-test.json\",lines=True)\n",
    "df_test['text'] = df_test['title'] + df_test['body']\n",
    "df_test['text'] =df_test['text'].apply(pre_process)\n",
    "\n",
    "# get test docs into a list\n",
    "docs_test=df_test['text'].tolist()\n",
    "docs_title=df_test['title'].tolist()\n",
    "docs_body=df_test['body'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb0e8ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        # TODO: Append score rounded off to 3 decimal places, in the score_vals list\n",
    "        score_vals.append(round(score, 3))\n",
    "        # TODO: Append fname to the feature_vals list\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da687e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Integrate War-Plugin for m2eclipse into Eclipse Project\n",
      "\n",
      "=====Body=====\n",
      "<p>I set up a small web project with JSF and Maven. Now I want to deploy on a Tomcat server. Is there a possibility to automate that like a button in Eclipse that automatically deploys the project to Tomcat?</p>\n",
      "\n",
      "<p>I read about a the <a href=\"http://maven.apache.org/plugins/maven-war-plugin/\" rel=\"nofollow noreferrer\">Maven War Plugin</a> but I couldn't find a tutorial how to integrate that into my process (eclipse/m2eclipse).</p>\n",
      "\n",
      "<p>Can you link me to help or try to explain it. Thanks.</p>\n",
      "\n",
      "===Keywords===\n",
      "eclipse 0.593\n",
      "war 0.317\n",
      "integrate 0.281\n",
      "maven 0.273\n",
      "tomcat 0.27\n",
      "project 0.239\n",
      "plugin 0.214\n",
      "automate 0.157\n",
      "jsf 0.152\n",
      "possibility 0.146\n"
     ]
    }
   ],
   "source": [
    "#you only needs to do this once\n",
    "feature_names=cv.get_feature_names_out()\n",
    "\n",
    "# get the document that we want to extract keywords from\n",
    "doc=docs_test[0]\n",
    "\n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    "\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "\n",
    "# now print the results\n",
    "print(\"\\n=====Title=====\")\n",
    "print(docs_title[0])\n",
    "print(\"\\n=====Body=====\")\n",
    "print(docs_body[0])\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd31fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the common code into several methods\n",
    "def get_keywords(idx):\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([docs_test[idx]]))\n",
    "\n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def print_results(idx,keywords):\n",
    "    # now print the results\n",
    "    print(\"\\n=====Title=====\")\n",
    "    print(docs_title[idx])\n",
    "    print(\"\\n=====Body=====\")\n",
    "    print(docs_body[idx])\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keywords:\n",
    "        print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86b1b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "SQL Import Wizard - Error\n",
      "\n",
      "=====Body=====\n",
      "<p>I have a CSV file that I'm trying to import into SQL Management Server Studio.</p>\n",
      "\n",
      "<p>In Excel, the column giving me trouble looks like this:\n",
      "<a href=\"https://i.stack.imgur.com/pm0uS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pm0uS.png\" alt=\"enter image description here\"></a></p>\n",
      "\n",
      "<p>Tasks > import data > Flat Source File > select file</p>\n",
      "\n",
      "<p><a href=\"https://i.stack.imgur.com/G4b6I.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/G4b6I.png\" alt=\"enter image description here\"></a></p>\n",
      "\n",
      "<p>I set the data type for this column to DT_NUMERIC, adjust the DataScale to 2 in order to get 2 decimal places, but when I click over to Preview, I see that it's clearly not recognizing the numbers appropriately:</p>\n",
      "\n",
      "<p><a href=\"https://i.stack.imgur.com/NZhiQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NZhiQ.png\" alt=\"enter image description here\"></a></p>\n",
      "\n",
      "<p>The column mapping for this column is set to type = decimal; precision 18; scale 2.</p>\n",
      "\n",
      "<p>Error message: Data Flow Task 1: Data conversion failed. The data conversion for column \"Amount\" returned status value 2 and status text \"The value could not be converted because of a potential loss of data.\".\n",
      " (SQL Server Import and Export Wizard)</p>\n",
      "\n",
      "<p>Can someone identify where I'm going wrong here?  Thanks!</p>\n",
      "\n",
      "===Keywords===\n",
      "column 0.365\n",
      "import 0.286\n",
      "data 0.283\n",
      "wizard 0.27\n",
      "decimal 0.227\n",
      "conversion 0.224\n",
      "sql 0.217\n",
      "status 0.164\n",
      "file 0.147\n",
      "appropriately 0.142\n"
     ]
    }
   ],
   "source": [
    "idx=120\n",
    "keywords=get_keywords(idx)\n",
    "print_results(idx,keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e71f0513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>serializing a private struct can it be done i ...</td>\n",
       "      <td>{'eclipse': 0.593, 'war': 0.317, 'integrate': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how do i prevent floated right content from ov...</td>\n",
       "      <td>{'evaluate': 0.472, 'content': 0.403, 'console...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gradle command line i m trying to run a shell ...</td>\n",
       "      <td>{'appdomain': 0.409, 'dynamic': 0.384, 'perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loop variable as parameter in asynchronous fun...</td>\n",
       "      <td>{'image': 0.424, 'jpg': 0.412, 'background': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>canot get the href value hi i need to valid th...</td>\n",
       "      <td>{'uri': 0.371, 'bitmap': 0.318, 'intent': 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>how to unbind click and click submit button in...</td>\n",
       "      <td>{'delphi': 0.617, 'compatible': 0.365, 'win': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>swaggerui auth redirect swaggeruiauth of null ...</td>\n",
       "      <td>{'node': 0.547, 'selectsinglenode': 0.304, 'nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ssrs value display error for ssrs conditional ...</td>\n",
       "      <td>{'logo': 0.549, 'step': 0.33, 'triangle': 0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>accessing and changing a class instance from a...</td>\n",
       "      <td>{'length': 0.426, 'ev': 0.415, 'introduce': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>how to print the current time in the format da...</td>\n",
       "      <td>{'oauth': 0.388, 'localhost': 0.383, 'sdk': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   doc  \\\n",
       "0    serializing a private struct can it be done i ...   \n",
       "1    how do i prevent floated right content from ov...   \n",
       "2    gradle command line i m trying to run a shell ...   \n",
       "3    loop variable as parameter in asynchronous fun...   \n",
       "4    canot get the href value hi i need to valid th...   \n",
       "..                                                 ...   \n",
       "495  how to unbind click and click submit button in...   \n",
       "496  swaggerui auth redirect swaggeruiauth of null ...   \n",
       "497  ssrs value display error for ssrs conditional ...   \n",
       "498  accessing and changing a class instance from a...   \n",
       "499  how to print the current time in the format da...   \n",
       "\n",
       "                                              keywords  \n",
       "0    {'eclipse': 0.593, 'war': 0.317, 'integrate': ...  \n",
       "1    {'evaluate': 0.472, 'content': 0.403, 'console...  \n",
       "2    {'appdomain': 0.409, 'dynamic': 0.384, 'perfor...  \n",
       "3    {'image': 0.424, 'jpg': 0.412, 'background': 0...  \n",
       "4    {'uri': 0.371, 'bitmap': 0.318, 'intent': 0.30...  \n",
       "..                                                 ...  \n",
       "495  {'delphi': 0.617, 'compatible': 0.365, 'win': ...  \n",
       "496  {'node': 0.547, 'selectsinglenode': 0.304, 'nu...  \n",
       "497  {'logo': 0.549, 'step': 0.33, 'triangle': 0.32...  \n",
       "498  {'length': 0.426, 'ev': 0.415, 'introduce': 0....  \n",
       "499  {'oauth': 0.388, 'localhost': 0.383, 'sdk': 0....  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate tf-idf for all documents in your list. docs_test has 500 documents\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform(docs_test))\n",
    "\n",
    "results=[]\n",
    "for i in range(tf_idf_vector.shape[0]):\n",
    "    \n",
    "    # get vector for a single document\n",
    "    curr_vector=tf_idf_vector[i]\n",
    "    \n",
    "    #sort the tf-idf vector by descending order of scores\n",
    "    sorted_items=sort_coo(curr_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    \n",
    "    results.append(keywords)\n",
    "\n",
    "df=pd.DataFrame(zip(docs,results),columns=['doc','keywords'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b591264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "520e76e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0704365036222725, 0.0, 0.0, 0.03521825181113625, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.04402281476392031, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.04402281476392031, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# DATA BLOCK\n",
    "\n",
    "# Each new line (after '\\n') represents a new document\n",
    "text = '''he really really loves coffee\n",
    "my sister dislikes coffee\n",
    "my sister loves tea'''\n",
    "import math\n",
    "\n",
    "def main(text):\n",
    "    # split the text first into lines and then into lists of words\\\n",
    "    vocab=[]\n",
    "    docs = []\n",
    "    lines = text.splitlines()\n",
    "    s=''\n",
    "    for line in lines:\n",
    "        l=[]\n",
    "        for k,i in enumerate(line):\n",
    "            if(i==' '):\n",
    "                l.append(s)\n",
    "                vocab.append(s)\n",
    "                s=''\n",
    "            elif(k==len(line)-1):\n",
    "                l.append(s+i)\n",
    "                vocab.append(s+i)\n",
    "                s=''\n",
    "            else:\n",
    "                s=s+i\n",
    "        docs.append(l)\n",
    "\n",
    "    N = len(docs)\n",
    " \n",
    "    # create the vocabulary: the list of words that appear at least once\n",
    "\n",
    "    vocabulary = list(set(word for doc in docs for word in doc))\n",
    "    df = {}\n",
    "    tf = {}\n",
    "\n",
    "    for word in vocabulary:\n",
    "        tf[word] = [doc.count(word) / len(doc) for doc in docs]\n",
    "\n",
    "        df[word] = sum(1 for doc in docs if word in doc)\n",
    "\n",
    "\n",
    "    for doc_index, doc in enumerate(docs):\n",
    "        tfidf = []\n",
    "        for word in vocabulary:\n",
    "\n",
    "            word_tf = tf[word][doc_index]\n",
    "            word_df = df[word]\n",
    "            word_tfidf = word_tf*(math.log(N/(word_df+1),10))\n",
    "            tfidf.append(word_tfidf)\n",
    "        print(tfidf)\n",
    "main(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b0a888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e732f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
